{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This was part of a failed experiment please see vgg16-auto.ipynb \n",
    "### Training the bottleneck features of VGG16 \n",
    "##### Keras with Tensorflow backend\n",
    "Based on:\n",
    "- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html \n",
    "- https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Donwload the data sets and prepare the data\n",
    "A dataset of cats and dogs from an old kaggle competition:\n",
    "- https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "Copy 2000/800 validation/training images in the next folder structure\n",
    "- data\n",
    "  - train\n",
    "    - cats\n",
    "      - 1000 cats\n",
    "    - dogs\n",
    "      - 1000 dogs\n",
    "  - validation\n",
    "    - cats\n",
    "      - 400 cats\n",
    "    - dogs\n",
    "      - 400 dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the trained weights (527Mb)\n",
    "https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "\n",
    "Or, use Keras:\n",
    "```python\n",
    "from keras import applications\n",
    "vgg16 = applications.VGG16(include_top=True, weights='imagenet')\n",
    "vgg16.save('vgg16_with_top.h5')\n",
    "```\n",
    "\n",
    "I recommend the direct download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the VGG16 model and load the weights\n",
    "We are using **channel-last** configuration for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_29 (ZeroPaddi (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPaddi (None, 152, 152, 64)      0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 152, 152, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPaddi (None, 78, 78, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 78, 78, 128)       73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPaddi (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPaddi (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 42, 42, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPaddi (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 44, 44, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPaddi (None, 46, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 46, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPaddi (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPaddi (None, 27, 27, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 27, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPaddi (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 29, 29, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPaddi (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPaddi (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = Sequential()\n",
    "# Block 1\n",
    "vgg16.add(ZeroPadding2D((0, 0), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "vgg16.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "# Block 2\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "vgg16.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "# Block 3\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "vgg16.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "# Block 4\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3'))\n",
    "vgg16.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "# Block 5\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2'))\n",
    "vgg16.add(ZeroPadding2D((1, 1), input_shape=(img_width, img_height,3)))\n",
    "vgg16.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3'))\n",
    "vgg16.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16.load_weights('models/vgg/vgg16_weights.h5')\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "f = h5py.File('models/vgg/vgg16_weights.h5')\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(vgg16.layers) - 1:\n",
    "        # we don't look at the last two layers in the savefile (fully-connected and activation)\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    layer = vgg16.layers[k]\n",
    "\n",
    "    if layer.__class__.__name__ in ['Conv2D']:\n",
    "        weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n",
    "\n",
    "    layer.set_weights(weights)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next layers wont be trained\n",
      "zero_padding2d_29\n",
      "block1_conv1\n",
      "zero_padding2d_30\n",
      "block1_conv2\n",
      "block1_pool\n",
      "zero_padding2d_31\n",
      "block2_conv1\n",
      "zero_padding2d_32\n",
      "block2_conv2\n",
      "block2_pool\n",
      "zero_padding2d_33\n",
      "block3_conv1\n",
      "zero_padding2d_34\n",
      "block3_conv2\n",
      "zero_padding2d_35\n",
      "block3_conv3\n",
      "block3_pool\n",
      "zero_padding2d_36\n",
      "block4_conv1\n",
      "zero_padding2d_37\n",
      "block4_conv2\n",
      "zero_padding2d_38\n",
      "block4_conv3\n",
      "block4_pool\n",
      "zero_padding2d_39\n",
      "block5_conv1\n",
      "zero_padding2d_40\n",
      "block5_conv2\n",
      "zero_padding2d_41\n",
      "block5_conv3\n",
      "block5_pool\n"
     ]
    }
   ],
   "source": [
    "# we are only going to train the bottleneck features\n",
    "print(\"Next layers wont be trained\")\n",
    "for layer in vgg16.layers[:]:\n",
    "    print(layer.get_config()['name'],)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# top_model = Sequential()\n",
    "# top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "# top_model.add(Dense(256, activation='relu'))\n",
    "# top_model.add(Dropout(0.5))\n",
    "# top_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "vgg16.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load data and get bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "125/125 [==============================] - 597s   \n",
      "ellapsed time in seconds: 597.9180190563202\n",
      "Found 800 images belonging to 2 classes.\n",
      "50/50 [==============================] - 238s   \n",
      "ellapsed time in seconds: 238.74046516418457\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "start = time.time()\n",
    "bottleneck_features_train = vgg16.predict_generator(generator, nb_train_samples // batch_size, verbose=1)\n",
    "print(\"ellapsed time in seconds:\", (time.time()-start))\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "start = time.time()\n",
    "bottleneck_features_validation = vgg16.predict_generator(generator, nb_validation_samples // batch_size, verbose=1)\n",
    "print(\"ellapsed time in seconds:\", (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optional?\n",
    "np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 16s - loss: 7.6575 - acc: 0.5090 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 15s - loss: 7.3925 - acc: 0.5050 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 15s - loss: 7.2231 - acc: 0.5125 - val_loss: 1.1293 - val_acc: 0.7812\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 15s - loss: 6.4652 - acc: 0.5450 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 15s - loss: 4.9388 - acc: 0.6045 - val_loss: 1.8261 - val_acc: 0.6675\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 15s - loss: 1.0302 - acc: 0.7105 - val_loss: 0.4967 - val_acc: 0.8150\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.6018 - acc: 0.7430 - val_loss: 0.6036 - val_acc: 0.6625\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.6237 - acc: 0.7500 - val_loss: 0.4276 - val_acc: 0.8075\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.5235 - acc: 0.7740 - val_loss: 0.3705 - val_acc: 0.8500\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.5170 - acc: 0.7835 - val_loss: 0.5520 - val_acc: 0.7588\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.4567 - acc: 0.7940 - val_loss: 0.3754 - val_acc: 0.8512\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.4491 - acc: 0.7850 - val_loss: 0.5024 - val_acc: 0.8175\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.5032 - acc: 0.7950 - val_loss: 0.3709 - val_acc: 0.8475\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.4231 - acc: 0.8175 - val_loss: 0.3960 - val_acc: 0.8075\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.4073 - acc: 0.8270 - val_loss: 0.3507 - val_acc: 0.8650\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.4257 - acc: 0.8235 - val_loss: 0.3458 - val_acc: 0.8650\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.3790 - acc: 0.8300 - val_loss: 0.4792 - val_acc: 0.8187\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3828 - acc: 0.8235 - val_loss: 0.3777 - val_acc: 0.8462\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.3771 - acc: 0.8295 - val_loss: 0.4438 - val_acc: 0.8488\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3552 - acc: 0.8415 - val_loss: 0.3600 - val_acc: 0.8562\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3922 - acc: 0.8295 - val_loss: 0.4639 - val_acc: 0.8287\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3448 - acc: 0.8410 - val_loss: 0.4164 - val_acc: 0.8700\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3319 - acc: 0.8495 - val_loss: 0.5541 - val_acc: 0.8075\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3445 - acc: 0.8545 - val_loss: 0.3845 - val_acc: 0.8675\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3235 - acc: 0.8545 - val_loss: 0.3908 - val_acc: 0.8712\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3327 - acc: 0.8570 - val_loss: 0.4053 - val_acc: 0.8762\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3132 - acc: 0.8625 - val_loss: 0.4176 - val_acc: 0.8738\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2985 - acc: 0.8575 - val_loss: 0.4025 - val_acc: 0.8488\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3023 - acc: 0.8590 - val_loss: 0.3961 - val_acc: 0.8538\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3045 - acc: 0.8635 - val_loss: 0.4375 - val_acc: 0.8688\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3117 - acc: 0.8740 - val_loss: 0.3865 - val_acc: 0.8788\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.2801 - acc: 0.8705 - val_loss: 0.3978 - val_acc: 0.8650\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2841 - acc: 0.8695 - val_loss: 0.4123 - val_acc: 0.8800\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2887 - acc: 0.8740 - val_loss: 0.6643 - val_acc: 0.8462\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.3016 - acc: 0.8765 - val_loss: 0.4960 - val_acc: 0.8762\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2788 - acc: 0.8885 - val_loss: 0.5765 - val_acc: 0.8275\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2722 - acc: 0.8750 - val_loss: 0.3886 - val_acc: 0.8825\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2671 - acc: 0.8770 - val_loss: 0.4299 - val_acc: 0.8762\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2610 - acc: 0.8755 - val_loss: 0.5168 - val_acc: 0.7887\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.2729 - acc: 0.8805 - val_loss: 0.4590 - val_acc: 0.8838\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.2775 - acc: 0.8810 - val_loss: 0.6542 - val_acc: 0.8237\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2503 - acc: 0.8905 - val_loss: 0.4622 - val_acc: 0.8638\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2685 - acc: 0.8785 - val_loss: 0.4391 - val_acc: 0.8762\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2674 - acc: 0.8880 - val_loss: 0.4740 - val_acc: 0.8762\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2563 - acc: 0.8895 - val_loss: 0.4691 - val_acc: 0.8712\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2477 - acc: 0.8825 - val_loss: 0.4528 - val_acc: 0.8688\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.2435 - acc: 0.8885 - val_loss: 0.5038 - val_acc: 0.8575\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2500 - acc: 0.8885 - val_loss: 0.4979 - val_acc: 0.8675\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 15s - loss: 0.2467 - acc: 0.9000 - val_loss: 0.5664 - val_acc: 0.8325\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 16s - loss: 0.2450 - acc: 0.9015 - val_loss: 0.5726 - val_acc: 0.8712\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'top_model_weights_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-7f331382b5b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m           validation_data=(validation_data, validation_labels))\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_model_weights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ellapsed time in seconds:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_model_weights_path' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "print(\"ellapsed time in seconds:\", (time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(top_model_weights_path)\n",
    "top_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Combine vgg16 + top_model and tune fine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_29_input (Inp (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPaddi (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPaddi (None, 152, 152, 64)      0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 152, 152, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 76, 76, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPaddi (None, 78, 78, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 78, 78, 128)       73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPaddi (None, 80, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPaddi (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 42, 42, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPaddi (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 44, 44, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPaddi (None, 46, 46, 256)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 46, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPaddi (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPaddi (None, 27, 27, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 27, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPaddi (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 29, 29, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPaddi (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPaddi (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "sequential_9 (Sequential)    (None, 1)                 13107713  \n",
      "=================================================================\n",
      "Total params: 27,822,401\n",
      "Trainable params: 13,107,713\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "# top_model has the weights \n",
    "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:32]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "125/125 [==============================] - 864s - loss: 0.3617 - acc: 0.8460 - val_loss: 0.4041 - val_acc: 0.8688\n",
      "ellapsed time in seconds: 864.1313540935516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c8843dd30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "# fine-tune the model\n",
    "epochs_modified = 1\n",
    "output = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs_modified,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "print(\"ellapsed time in seconds:\", (time.time()-start))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model_weights = \"vgg16+top_model-train_2h_weights_only.h5\"\n",
    "model.save_weights(final_model_weights)\n",
    "final_model = \"vgg16+top_model-train2h.h5\"\n",
    "model.save(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Do predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import load_model\n",
    "# from https://gist.github.com/ragvri/6a28b08b9ad844bc66b90db7d7cebb17\n",
    "def predict_image_class(model, file, w, h):\n",
    "    x = load_img(file, target_size=(w, h))\n",
    "    x = img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    array = model.predict(x)\n",
    "    print(array)\n",
    "    if array[0][0] == 1:\n",
    "        print(\"dog\")\n",
    "    else:\n",
    "        print(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = load_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]]\n",
      "dog\n",
      "[[ 1.]]\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "predict_image_class(predictor, \"data/validation/dogs/dog.12199.jpg\", img_width, img_height)\n",
    "predict_image_class(predictor, \"data/validation/cats/cat.12100.jpg\", img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
